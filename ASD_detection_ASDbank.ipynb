{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2CZ4Ma5GkJf"
      },
      "outputs": [],
      "source": [
        "def read_text_file(file_path):\n",
        " os.chdir(file_path)\n",
        " final_file=[]\n",
        " last_file=[]\n",
        " # iterate through all file\n",
        " for file in os.listdir(file_path):\n",
        "    if os.path.isdir(file)==True:\n",
        "      file_path_new=file_path+\"/\"+file\n",
        "      for file in os.listdir(file_path_new):\n",
        "        if file.startswith(\".\"):\n",
        "            continue\n",
        "        if file.endswith(\".xml\"):\n",
        "            document = f\"{file_path_new}\"+\"/\"+file\n",
        "        # call read text file function\n",
        "            with open(document, 'r', errors=\"ignore\") as f:\n",
        "               final_file.append(XMLreader_new(f))\n",
        "    # Check whether file is in text format or not\n",
        "    else:\n",
        "        if file.startswith(\".\"):\n",
        "            continue\n",
        "        if file.endswith(\".xml\"):\n",
        "            document = f\"{file_path}\"+\"/\"+file\n",
        "        # call read text file function\n",
        "            with open(document, 'r',  errors=\"ignore\") as f:\n",
        "               final_file.append(XMLreader_new(f))\n",
        " return final_file\n",
        "\n",
        "def XMLreader(filename=''):\n",
        "  tree = parse(filename)\n",
        "  root = tree.getroot()\n",
        "  file=[]\n",
        "  sentence=[]\n",
        "  for elem in root:\n",
        "      for gchild in elem:\n",
        "                if gchild.text==None:\n",
        "                    if sentence!=[]:\n",
        "                      file.append(sentence)\n",
        "                      sentence=[]\n",
        "                      continue\n",
        "                else:\n",
        "                    sentence.append(gchild.text)\n",
        "  return file\n",
        "\n",
        "def XMLreader_comp(filename=''):\n",
        "  corpus_relation=[]\n",
        "  corpus_word=[]\n",
        "  sentence_relation=[]\n",
        "  sentence_word=[]\n",
        "  from lxml import etree\n",
        "  #xmldoc = minidom.parse(filename)\n",
        "  #itemlist = xmldoc.getElementsByTagName('relation')\n",
        "  #print(memoryElem.text)\n",
        "  tree = parse(filename)\n",
        "  root = tree.getroot()\n",
        "  for elem in tree.findall('.//{http://www.talkbank.org/ns/talkbank}w'):\n",
        "        print(elem.text)\n",
        "        gra=elem.find('.//{http://www.talkbank.org/ns/talkbank}gra')\n",
        "        if gra==None:\n",
        "            continue\n",
        "        elif gra.attrib['index'] == '1':\n",
        "            corpus_word.append(sentence_word)\n",
        "            corpus_relation.append(sentence_relation)\n",
        "            sentence_word=[]\n",
        "            sentence_relation=[]\n",
        "            sentence_word.append(elem.text)\n",
        "            sentence_relation.append(gra.attrib['relation'])\n",
        "        else:\n",
        "            sentence_word.append(elem.text)\n",
        "            sentence_relation.append(gra.attrib['relation'])\n",
        "  return corpus_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8ydhf-YYlp7"
      },
      "outputs": [],
      "source": [
        "def XMLreader_new(filename=''):\n",
        "  corpus_relation=[]\n",
        "  corpus_word=[]\n",
        "  sentence_relation=[]\n",
        "  sentence_word=[]\n",
        "  from lxml import etree\n",
        "  #xmldoc = minidom.parse(filename)\n",
        "  #itemlist = xmldoc.getElementsByTagName('relation')\n",
        "  #print(memoryElem.text)\n",
        "  tree = parse(filename)\n",
        "  root = tree.getroot()\n",
        "  for u in root.findall(\".//{http://www.talkbank.org/ns/talkbank}u\"):\n",
        "        sentence = []\n",
        "        for w in u.findall(\".//{http://www.talkbank.org/ns/talkbank}w\"):\n",
        "            sentence.append(w.text)\n",
        "        corpus_word.append(sentence)\n",
        "  return corpus_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5GPx7ZoG2ow"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from xml.etree.ElementTree import parse\n",
        "Eigsti=read_text_file(\"/content/drive/MyDrive/Colab_Notebooks/ASD/Eigsti\")\n",
        "Eigsti_label=[1]*16+[0]*32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH-AgSF6JwSo"
      },
      "outputs": [],
      "source": [
        "Flusberg=read_text_file(\"/content/drive/MyDrive/Colab_Notebooks/ASD/Flusberg\")\n",
        "Flusberg_label=[1]*6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gbUAPyyJ3sB",
        "outputId": "001a42c1-7351-4f37-ad5b-4a1a5754a6a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22\n",
            "35\n",
            "46\n",
            "56\n",
            "64\n"
          ]
        }
      ],
      "source": [
        "numbers=[10, 12, 13, 11, 10, 8]\n",
        "new_Flusberg=[]\n",
        "new_Flusberg.append(Flusberg[0:10])\n",
        "file=[]\n",
        "count=1\n",
        "current=10\n",
        "for number in range(len(Flusberg)):\n",
        "  file=file+Flusberg[number]\n",
        "  if number==current:\n",
        "    new_Flusberg.append(file)\n",
        "    file=[]\n",
        "    current=current+numbers[count]\n",
        "    print(current)\n",
        "    count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-OJG6J0S_q8"
      },
      "outputs": [],
      "source": [
        "QuigleyMcNally1=read_text_file(\"/content/drive/MyDrive/Colab_Notebooks/ASD/QuigleyMcNally/HR-xml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk7Xyv2MOGjF",
        "outputId": "7af75fdd-cf8a-4259-deb0-0c470e483924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24\n",
            "35\n",
            "46\n",
            "54\n",
            "63\n",
            "75\n",
            "86\n",
            "94\n",
            "105\n"
          ]
        }
      ],
      "source": [
        "numbers=[13,11, 11, 11,8,9,12,11,8,11]\n",
        "new_QuigleyMcNally1=[]\n",
        "new_QuigleyMcNally1.append(QuigleyMcNally1[0:13])\n",
        "file=[]\n",
        "count=1\n",
        "current=13\n",
        "for number in range(len(QuigleyMcNally1)):\n",
        "  file=file+QuigleyMcNally1[number]\n",
        "  if number==current:\n",
        "    new_QuigleyMcNally1.append(file)\n",
        "    file=[]\n",
        "    current=current+numbers[count]\n",
        "    print(current)\n",
        "    count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTVKwwFaRPE4"
      },
      "outputs": [],
      "source": [
        "QuigleyMcNally1_label=[1, 1, 1, 0, 1, 0, 1, 1, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX_phWTtMln-"
      },
      "outputs": [],
      "source": [
        "QuigleyMcNally2=read_text_file(\"/content/drive/MyDrive/Colab_Notebooks/ASD/QuigleyMcNally/LR-xml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj21Ggw5QTAa",
        "outputId": "3d7af3b6-47a1-4c71-f8e3-29a5f67b7aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22\n",
            "33\n",
            "43\n",
            "54\n",
            "65\n",
            "76\n",
            "87\n",
            "98\n"
          ]
        }
      ],
      "source": [
        "numbers=[11,11, 11, 10,11,11,11,11, 11]\n",
        "new_QuigleyMcNally2=[]\n",
        "new_QuigleyMcNally2.append(QuigleyMcNally2[0:11])\n",
        "file=[]\n",
        "count=1\n",
        "current=11\n",
        "for number in range(len(QuigleyMcNally2)):\n",
        "  file=file+QuigleyMcNally2[number]\n",
        "  if number==current:\n",
        "    new_QuigleyMcNally2.append(file)\n",
        "    file=[]\n",
        "    current=current+numbers[count]\n",
        "    print(current)\n",
        "    count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk3wFivVQ1Ki"
      },
      "outputs": [],
      "source": [
        "QuigleyMcNally2_label=[0, 0, 0, 0, 0, 1, 0, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVFXXM1ZZrpy"
      },
      "outputs": [],
      "source": [
        "Rollins=read_text_file(\"/content/drive/MyDrive/Colab_Notebooks/ASD/Rollins\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dy9jD0DYxgM",
        "outputId": "86882bd4-9f31-4c30-877f-66e23edfd263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "13\n",
            "17\n",
            "21\n"
          ]
        }
      ],
      "source": [
        "numbers=[4, 4, 5, 4, 4]\n",
        "new_Rollins=[]\n",
        "new_Rollins.append(Rollins[0:4])\n",
        "file=[]\n",
        "count=1\n",
        "current=4\n",
        "for number in range(len(Rollins)):\n",
        "  file=file+Rollins[number]\n",
        "  if number==current:\n",
        "    new_Rollins.append(file)\n",
        "    file=[]\n",
        "    current=current+numbers[count]\n",
        "    print(current)\n",
        "    count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XxIF7q1Nu26"
      },
      "outputs": [],
      "source": [
        "Rollins_label=[1]*5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyKp4Q6FR765"
      },
      "outputs": [],
      "source": [
        "all_data=new_Rollins+new_QuigleyMcNally2+new_QuigleyMcNally1+new_Flusberg+Eigsti\n",
        "all_label=Rollins_label+QuigleyMcNally2_label+QuigleyMcNally1_label+Flusberg_label+Eigsti_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69YN2d3Cau4d"
      },
      "outputs": [],
      "source": [
        "# change the OS to use your project folder as the working directory\n",
        "project_folder = \"/content/drive/MyDrive/Colab_Notebooks/ASD/\"\n",
        "os.chdir(project_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kdCjKYBioNc"
      },
      "outputs": [],
      "source": [
        "Eigsti = [[' '.join(filter(None, lst)) for lst in sublist] for sublist in Eigsti]\n",
        "new_Flusberg = [flatten_and_join(sublist).strip() for sublist in new_Flusberg]\n",
        "new_QuigleyMcNally1 = [flatten_and_join(sublist).strip() for sublist in new_QuigleyMcNally1]\n",
        "new_QuigleyMcNally2 = [flatten_and_join(sublist).strip() for sublist in new_QuigleyMcNally2]\n",
        "new_Rollins = [flatten_and_join(sublist).strip() for sublist in new_Rollins]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukzezEHfi-Nq"
      },
      "outputs": [],
      "source": [
        "def flatten_and_join(data):\n",
        "    if isinstance(data, list):\n",
        "        return ' '.join(filter(None, [flatten_and_join(item) for item in data if item is not None]))\n",
        "    else:\n",
        "        return str(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIMJ8FsSeFEj"
      },
      "source": [
        "### **chatgpt 4o**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3al9fq0tl5xy",
        "outputId": "716580d4-f968-4772-a46c-a2cf50297f55"
      },
      "outputs": [],
      "source": [
        "#baseline method chatgpt 4o\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Assuming all_data is your variable containing the nested lists\n",
        "# Example:\n",
        "# all_data = [[['you', 'have', 'fun', 1], ['alright', 0]], ...]\n",
        "\n",
        "# Flatten and join sentences, extract labels\n",
        "def flatten_and_join(data):\n",
        "    if isinstance(data, list):\n",
        "        result = []\n",
        "        for item in data:\n",
        "            if isinstance(item, list):\n",
        "                result.extend(flatten_and_join(item))\n",
        "            else:\n",
        "                result.append(str(item))\n",
        "        return result\n",
        "    else:\n",
        "        return [str(data)]\n",
        "\n",
        "flattened_data = []\n",
        "labels = []\n",
        "\n",
        "# Process each participant's data\n",
        "for participant_data in all_data:\n",
        "    text_list = []\n",
        "    label = None\n",
        "    for entry in participant_data:\n",
        "        if isinstance(entry, list):\n",
        "            text_list.extend(flatten_and_join(entry[:-1]))\n",
        "            #label_list = flatten_and_join(entry[-1:])\n",
        "            #label = int(label_list[0])\n",
        "    text = ' '.join(filter(None, text_list))\n",
        "    flattened_data.append(text)\n",
        "    #labels.append(label)\n",
        "\n",
        "# Convert text data to numerical features\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(flattened_data)\n",
        "y = np.array(all_label)\n",
        "\n",
        "# Define the model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Define custom scoring functions\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "# Create scorers\n",
        "scorers = {\n",
        "    'Accuracy':make_scorer(accuracy_score),\n",
        "    'f1_score': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(specificity_score)\n",
        "}\n",
        "\n",
        "# Perform 5-Fold Cross-Validation\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "results = {metric: cross_val_score(model, X, y, cv=cv, scoring=scorers[metric]) for metric in scorers}\n",
        "\n",
        "# Print the results\n",
        "for metric, scores in results.items():\n",
        "    print(f\"{metric.capitalize()} Scores: {scores}\")\n",
        "    print(f\"Mean {metric.capitalize()}: {scores.mean()}\")\n",
        "    print(f\"Standard Deviation: {scores.std()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ektWLiM5x8ZL",
        "outputId": "8035af76-2217-4493-9370-12f79e7480a3"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# List of items that score 1 point if \"Definitely agree\" or \"Slightly agree\"\n",
        "positive_score_items = [2, 4, 5, 6, 7, 9, 12, 13, 16, 18, 19, 20, 21, 22, 23, 26, 33, 35, 39, 41, 42, 43, 45, 46]\n",
        "\n",
        "# List of items that score 1 point if \"Definitely disagree\" or \"Slightly disagree\"\n",
        "negative_score_items = [1, 3, 8, 10, 11, 14, 15, 17, 24, 25, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 44, 47, 48, 49, 50]\n",
        "\n",
        "# Calculate AQ scores for each participant\n",
        "def calculate_aq_scores(participants):\n",
        "    aq_scores = []\n",
        "    for participant in participants:\n",
        "        score = 0\n",
        "        responses = participant['responses']\n",
        "        for idx, response in enumerate(responses, start=1):\n",
        "            if idx in positive_score_items and response in [1, 2]:  # 1: Definitely agree, 2: Slightly agree\n",
        "                score += 1\n",
        "            elif idx in negative_score_items and response in [3, 4]:  # 3: Slightly disagree, 4: Definitely disagree\n",
        "                score += 1\n",
        "        aq_scores.append({'id': participant['id'], 'score': score})\n",
        "    return aq_scores\n",
        "\n",
        "# Assuming `all_data` is the variable containing the nested lists of text data and labels\n",
        "def flatten_and_join(data):\n",
        "    if isinstance(data, list):\n",
        "        result = []\n",
        "        for item in data:\n",
        "            if isinstance(item, list):\n",
        "                result.extend(flatten_and_join(item))\n",
        "            else:\n",
        "                result.append(str(item))\n",
        "        return result\n",
        "    else:\n",
        "        return [str(data)]\n",
        "\n",
        "# Flatten the data and prepare for model training\n",
        "def prepare_data_for_model(all_data):\n",
        "    flattened_data = []\n",
        "    for entry in all_data:\n",
        "        if isinstance(entry, list):\n",
        "            text_list = flatten_and_join(entry)\n",
        "            text = ' '.join(filter(None, text_list))\n",
        "            flattened_data.append(text)\n",
        "    return flattened_data\n",
        "\n",
        "# Define custom scoring functions\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "# Main function to run the process\n",
        "def main(all_data, all_labels):\n",
        "    # Step 1: Calculate AQ Scores\n",
        "    participants = [{'id': idx, 'responses': entry} for idx, entry in enumerate(all_data)]\n",
        "    aq_scores = calculate_aq_scores(participants)\n",
        "    aq_score_values = [participant['score'] for participant in aq_scores]\n",
        "\n",
        "    # Step 2: Prepare data for cross-validation\n",
        "    flattened_data = prepare_data_for_model(all_data)\n",
        "    vectorizer = CountVectorizer()\n",
        "    X_text = vectorizer.fit_transform(flattened_data).toarray()\n",
        "    X_aq = np.array(aq_score_values).reshape(-1, 1)\n",
        "\n",
        "    # Combine text features with AQ scores\n",
        "    X_combined = np.hstack((X_text, X_aq))\n",
        "    y = np.array(all_labels)\n",
        "\n",
        "    # Step 3: Balance the classes using SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X_combined, y)\n",
        "\n",
        "    # Step 4: Define the model and perform 5-fold cross-validation\n",
        "    model = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
        "    scorers = {\n",
        "        'Accuracy':make_scorer(accuracy_score),\n",
        "        'f1_score': make_scorer(f1_score),\n",
        "        'sensitivity': make_scorer(recall_score),\n",
        "        'specificity': make_scorer(specificity_score)\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5)\n",
        "    after_results = {metric: cross_val_score(model, X_resampled, y_resampled, cv=cv, scoring=scorers[metric]) for metric in scorers}\n",
        "\n",
        "    # Print the results\n",
        "    for metric, scores in after_results.items():\n",
        "        print(f\"{metric.capitalize()} Scores: {scores}\")\n",
        "        print(f\"Mean {metric.capitalize()}: {scores.mean()}\")\n",
        "        print(f\"Standard Deviation: {scores.std()}\")\n",
        "\n",
        "    return after_results\n",
        "# Assuming `all_data` and `all_labels` are provided and contain the necessary data\n",
        "after_results=main(all_data, all_label)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7kg6LLReKdp"
      },
      "source": [
        "### **chatgpt 4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bUYXr0NywFu",
        "outputId": "7956cd6d-a571-4d47-9645-c87acb7fd226"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Assuming `all_data` is the variable containing the nested lists of text data and labels\n",
        "def flatten_and_join(data):\n",
        "    if isinstance(data, list):\n",
        "        result = []\n",
        "        for item in data:\n",
        "            if isinstance(item, list):\n",
        "                result.extend(flatten_and_join(item))\n",
        "            else:\n",
        "                result.append(str(item))\n",
        "        return result\n",
        "    else:\n",
        "        return [str(data)]\n",
        "\n",
        "# Flatten the data and prepare for model training\n",
        "def prepare_data_for_model(all_data):\n",
        "    flattened_data = []\n",
        "    for entry in all_data:\n",
        "        if isinstance(entry, list):\n",
        "            text_list = flatten_and_join(entry)\n",
        "            text = ' '.join(filter(None, text_list))\n",
        "            flattened_data.append(text)\n",
        "    return flattened_data\n",
        "\n",
        "# Prepare the flattened data\n",
        "flattened_data = prepare_data_for_model(all_data)\n",
        "\n",
        "# Convert the flattened data into a DataFrame\n",
        "df = pd.DataFrame(flattened_data, columns=['text'])\n",
        "\n",
        "\n",
        "# Assume the target variable is 'ASD' and convert to binary format if necessary\n",
        "df['ASD'] = all_label\n",
        "\n",
        "# Separate features and target\n",
        "X = df['text']\n",
        "y = df['ASD']\n",
        "\n",
        "# Create a pipeline to vectorize text, standardize the data, and apply logistic regression\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('scaler', StandardScaler(with_mean=False)),\n",
        "    ('logreg', LogisticRegression(solver='liblinear'))\n",
        "])\n",
        "\n",
        "# Define custom scoring functions\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "scoring = {\n",
        "    'Accuracy':make_scorer(accuracy_score),\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(specificity_score)\n",
        "}\n",
        "\n",
        "# Perform 5-fold cross-validation with multiple metrics\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "scores = cross_validate(pipeline, X, y, cv=cv, scoring=scoring, return_train_score=False, error_score='raise')\n",
        "\n",
        "\n",
        "# Calculate mean and standard deviation for each metric\n",
        "\n",
        "mean_acc = np.mean(scores['test_Accuracy'])\n",
        "std_acc = np.std(scores['test_Accuracy'])\n",
        "mean_f1 = np.mean(scores['test_f1'])\n",
        "std_f1 = np.std(scores['test_f1'])\n",
        "mean_sensitivity = np.mean(scores['test_sensitivity'])\n",
        "std_sensitivity = np.std(scores['test_sensitivity'])\n",
        "mean_specificity = np.mean(scores['test_specificity'])\n",
        "std_specificity = np.std(scores['test_specificity'])\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: Mean={mean_acc:.3f}, Std={std_acc:.3f}\")\n",
        "print(f\"F1 Score: Mean={mean_f1:.3f}, Std={std_f1:.3f}\")\n",
        "print(f\"Sensitivity (Recall): Mean={mean_sensitivity:.3f}, Std={std_sensitivity:.3f}\")\n",
        "print(f\"Specificity: Mean={mean_specificity:.3f}, Std={std_specificity:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF6FwMWy9mLt"
      },
      "outputs": [],
      "source": [
        "# Keywords mapping for Autism Quotient (AQ) questionnaire items\n",
        "aq_keywords = {\n",
        "    1: [\"social\", \"friends\", \"group\", \"together\", \"team\"],\n",
        "    2: [\"routine\", \"habitual\", \"repeat\", \"same\", \"consistent\"],\n",
        "    3: [\"imagine\", \"visualize\", \"picture\", \"see\", \"dream\"],\n",
        "    4: [\"absorbed\", \"focused\", \"intense\", \"obsessed\", \"fixated\"],\n",
        "    5: [\"sounds\", \"hear\", \"notice\", \"sensitive\", \"audio\"],\n",
        "    6: [\"numbers\", \"plates\", \"details\", \"remember\", \"observe\"],\n",
        "    7: [\"impolite\", \"rude\", \"misunderstand\", \"social cues\", \"etiquette\"],\n",
        "    8: [\"imagine\", \"characters\", \"visualize\", \"story\", \"picture\"],\n",
        "    9: [\"dates\", \"history\", \"remember\", \"fascinated\", \"chronological\"],\n",
        "    10: [\"social\", \"conversations\", \"multitask\", \"attentive\", \"listen\"],\n",
        "    11: [\"social\", \"easy\", \"comfortable\", \"enjoy\", \"mingle\"],\n",
        "    12: [\"details\", \"notice\", \"observe\", \"aware\", \"perceive\"],\n",
        "    13: [\"library\", \"quiet\", \"books\", \"read\", \"solitude\"],\n",
        "    14: [\"stories\", \"imagine\", \"creative\", \"fiction\", \"make up\"],\n",
        "    15: [\"people\", \"emotions\", \"relationships\", \"drawn\", \"social\"],\n",
        "    16: [\"interests\", \"passionate\", \"upset\", \"hobbies\", \"focused\"],\n",
        "    17: [\"chit-chat\", \"small talk\", \"socialize\", \"casual\", \"talkative\"],\n",
        "    18: [\"talk\", \"monologue\", \"dominate\", \"interrupt\", \"verbose\"],\n",
        "    19: [\"numbers\", \"math\", \"interest\", \"statistics\", \"data\"],\n",
        "    20: [\"characters\", \"intentions\", \"reading\", \"understand\", \"motives\"],\n",
        "    21: [\"fiction\", \"reading\", \"novels\", \"books\", \"stories\"],\n",
        "    22: [\"friends\", \"make\", \"social\", \"hard\", \"difficult\"],\n",
        "    23: [\"patterns\", \"notice\", \"regularities\", \"order\", \"arrange\"],\n",
        "    24: [\"theatre\", \"plays\", \"performances\", \"acting\", \"stage\"],\n",
        "    25: [\"routine\", \"disturbed\", \"upset\", \"change\", \"flexible\"],\n",
        "    26: [\"conversation\", \"talk\", \"silent\", \"speak\", \"communicate\"],\n",
        "    27: [\"subtext\", \"implied\", \"read between\", \"understand\", \"hints\"],\n",
        "    28: [\"whole\", \"details\", \"big picture\", \"overview\", \"general\"],\n",
        "    29: [\"memory\", \"numbers\", \"forget\", \"recall\", \"phone\"],\n",
        "    30: [\"changes\", \"notice\", \"details\", \"different\", \"observe\"],\n",
        "    31: [\"bored\", \"listening\", \"attention\", \"interest\", \"engage\"],\n",
        "    32: [\"multitask\", \"simultaneous\", \"multiple\", \"juggle\", \"several\"],\n",
        "    33: [\"phone\", \"speak\", \"turn\", \"conversation\", \"talk\"],\n",
        "    34: [\"spontaneous\", \"impulse\", \"sudden\", \"unplanned\", \"unexpected\"],\n",
        "    35: [\"joke\", \"humor\", \"laugh\", \"understand\", \"funny\"],\n",
        "    36: [\"feelings\", \"emotions\", \"face\", \"expressions\", \"read\"],\n",
        "    37: [\"quick\", \"adapt\", \"switch\", \"responsive\", \"interrupt\"],\n",
        "    38: [\"social\", \"chit-chat\", \"talk\", \"converse\", \"small talk\"],\n",
        "    39: [\"repetitive\", \"same\", \"monologue\", \"obsess\", \"topic\"],\n",
        "    40: [\"pretend\", \"play\", \"games\", \"imagine\", \"children\"],\n",
        "    41: [\"collect\", \"information\", \"categories\", \"types\", \"data\"],\n",
        "    42: [\"imagine\", \"someone else\", \"empathize\", \"perspective\", \"viewpoint\"],\n",
        "    43: [\"plan\", \"organize\", \"prepare\", \"arrange\", \"schedule\"],\n",
        "    44: [\"social\", \"events\", \"parties\", \"gatherings\", \"enjoy\"],\n",
        "    45: [\"intentions\", \"people\", \"understand\", \"predict\", \"behavior\"],\n",
        "    46: [\"anxious\", \"new\", \"situations\", \"stress\", \"uncomfortable\"],\n",
        "    47: [\"meet\", \"new people\", \"enjoy\", \"socialize\", \"friendly\"],\n",
        "    48: [\"diplomat\", \"tactful\", \"negotiate\", \"smooth\", \"mediate\"],\n",
        "    49: [\"birthdays\", \"remember\", \"dates\", \"forget\", \"celebrations\"],\n",
        "    50: [\"pretend\", \"play\", \"games\", \"children\", \"imagination\"]\n",
        "}\n",
        "\n",
        "# Use this dictionary to assess text data for AQ responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdxu4QXR1fse",
        "outputId": "4c2d3e43-8cdb-4a90-b41e-11557c0a4735"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, confusion_matrix\n",
        "\n",
        "def flatten_and_join(data):\n",
        "    \"\"\" Recursively flattens a nested list and converts each element into a string. \"\"\"\n",
        "    result = []\n",
        "    if isinstance(data, list):\n",
        "        for item in data:\n",
        "            if isinstance(item, list):\n",
        "                result.extend(flatten_and_join(item))\n",
        "            else:\n",
        "                result.append(str(item))\n",
        "    else:\n",
        "        result.append(str(data))\n",
        "    return result\n",
        "# Function to simulate AQ responses based on text analysis\n",
        "def generate_responses(text, keywords):\n",
        "    responses = []\n",
        "    for i in range(1, 51):  # Assuming there are 50 AQ items\n",
        "        item_keywords = keywords.get(i, [])\n",
        "        response = 'Definitely disagree'  # Default response\n",
        "        if any(keyword in text for keyword in item_keywords):\n",
        "            response = 'Definitely agree'\n",
        "        responses.append(response)\n",
        "    return responses\n",
        "\n",
        "# Function to calculate AQ score from responses\n",
        "def calculate_aq_score(responses):\n",
        "    agree_points = {2, 4, 5, 6, 7, 9, 12, 13, 16, 18, 19, 20, 21, 22, 23, 26, 33, 35, 39, 41, 42, 43, 45, 46}\n",
        "    disagree_points = {1, 3, 8, 10, 11, 14, 15, 17, 24, 25, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 44, 47, 48, 49, 50}\n",
        "    score = 0\n",
        "    for i, response in enumerate(responses, 1):\n",
        "        if ((i in agree_points and 'agree' in response.lower()) or\n",
        "            (i in disagree_points and 'disagree' in response.lower())):\n",
        "            score += 1\n",
        "    return score\n",
        "'''\n",
        "# Example text data (replace this with actual data loading and preprocessing)\n",
        "flattened_data = prepare_data_for_model(all_data)\n",
        "'''\n",
        "# Simulate AQ responses and calculate scores\n",
        "responses = [generate_responses(text, aq_keywords) for text in flattened_data]\n",
        "aq_scores = [calculate_aq_score(resp) for resp in responses]\n",
        "\n",
        "def prepare_data_for_model(all_data, all_scores):\n",
        "    \"\"\" Prepares text data for model training by flattening nested lists, joining text elements, and appending numeric scores as text. \"\"\"\n",
        "    flattened_data = []\n",
        "    for entry, score in zip(all_data, all_scores):  # Include score in the loop\n",
        "        text_list = flatten_and_join(entry)\n",
        "        text = ' '.join(filter(None, text_list))\n",
        "        text_with_score = f\"{text} {str(score)}\"  # Append score as a string to the text\n",
        "        flattened_data.append(text_with_score)\n",
        "    return flattened_data\n",
        "\n",
        "flattened_data = prepare_data_for_model(all_data, aq_scores)\n",
        "df = pd.DataFrame({'text': flattened_data, 'ASD': all_label})\n",
        "\n",
        "X = df['text']\n",
        "y = df['ASD']\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('scaler', StandardScaler(with_mean=False)),  # Use with_mean=False to handle sparse data\n",
        "    ('logreg', LogisticRegression(solver='liblinear'))\n",
        "])\n",
        "\n",
        "# Define custom scoring functions\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "scoring = {\n",
        "    'Accuracy':make_scorer(accuracy_score),\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(specificity_score)\n",
        "}\n",
        "\n",
        "# Perform 5-fold cross-validation with multiple metrics\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "scores = cross_validate(pipeline, X, y, cv=cv, scoring=scoring, return_train_score=False, error_score='raise')\n",
        "\n",
        "# Calculate mean and standard deviation for each metric\n",
        "\n",
        "mean_acc = np.mean(scores['test_Accuracy'])\n",
        "std_acc = np.std(scores['test_Accuracy'])\n",
        "mean_f1 = np.mean(scores['test_f1'])\n",
        "std_f1 = np.std(scores['test_f1'])\n",
        "mean_sensitivity = np.mean(scores['test_sensitivity'])\n",
        "std_sensitivity = np.std(scores['test_sensitivity'])\n",
        "mean_specificity = np.mean(scores['test_specificity'])\n",
        "std_specificity = np.std(scores['test_specificity'])\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: Mean={mean_acc:.3f}, Std={std_acc:.3f}\")\n",
        "print(f\"F1 Score: Mean={mean_f1:.3f}, Std={std_f1:.3f}\")\n",
        "print(f\"Sensitivity (Recall): Mean={mean_sensitivity:.3f}, Std={std_sensitivity:.3f}\")\n",
        "print(f\"Specificity: Mean={mean_specificity:.3f}, Std={std_specificity:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6TU-uhfeOyq"
      },
      "source": [
        "### **claude 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkF1Iw4ZhaQW",
        "outputId": "3eb6ad16-df29-4b79-d655-1be96b24de8d"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'all_data' is a list of lists containing the text data\n",
        "# and 'all_label' is a list containing the corresponding ASD labels (0 or 1)\n",
        "\n",
        "def flatten_list(nested_list):\n",
        "    flattened = []\n",
        "    for element in nested_list:\n",
        "        if isinstance(element, list):\n",
        "            flattened.extend(flatten_list(element))\n",
        "        else:\n",
        "            flattened.append(str(element))\n",
        "    return flattened\n",
        "\n",
        "# Flatten the nested lists into a single list of strings\n",
        "all_data_flattened = [' '.join(flatten_list(doc)) for doc in all_data]\n",
        "\n",
        "# Preprocess the text data\n",
        "vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 3), min_df=5)\n",
        "X = vectorizer.fit_transform(all_data_flattened)\n",
        "y = np.array(all_label)  # Convert 'y' to a NumPy array\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = [\n",
        "    LogisticRegression(class_weight='balanced'),\n",
        "    SVC(kernel='linear', class_weight='balanced'),\n",
        "    RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
        "]\n",
        "\n",
        "# Initialize stratified k-fold cross-validation\n",
        "kf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "# Perform 5-fold cross-validation for each classifier\n",
        "for classifier in classifiers:\n",
        "    print(f\"Classifier: {classifier.__class__.__name__}\")\n",
        "\n",
        "    accuracies=[]\n",
        "    f1_scores = []\n",
        "    sensitivities = []\n",
        "    specificities = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Train the classifier\n",
        "        classifier.fit(X_train, y_train)\n",
        "\n",
        "        # Predict the labels for the test set\n",
        "        y_pred = classifier.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        acc=accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        sensitivity = recall_score(y_test, y_pred)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "        specificity = tn / (tn + fp)\n",
        "\n",
        "        # Append scores to the lists\n",
        "        accuracies.append(acc)\n",
        "        f1_scores.append(f1)\n",
        "        sensitivities.append(sensitivity)\n",
        "        specificities.append(specificity)\n",
        "\n",
        "    # Print the average scores and standard deviations for each classifier\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(accuracies), np.std(accuracies) * 2))\n",
        "    print(\"F1 Score: %0.2f (+/- %0.2f)\" % (np.mean(f1_scores), np.std(f1_scores) * 2))\n",
        "    print(\"Sensitivity: %0.2f (+/- %0.2f)\" % (np.mean(sensitivities), np.std(sensitivities) * 2))\n",
        "    print(\"Specificity: %0.2f (+/- %0.2f)\" % (np.mean(specificities), np.std(specificities) * 2))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSH6vXafhblw",
        "outputId": "6e116412-3905-4443-a73b-013a0f143111"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Assuming 'all_data' is a list of lists containing the text data\n",
        "# and 'all_label' is a list containing the corresponding ASD labels (0 or 1)\n",
        "\n",
        "def flatten_list(nested_list):\n",
        "    flattened = []\n",
        "    for element in nested_list:\n",
        "        if isinstance(element, list):\n",
        "            flattened.extend(flatten_list(element))\n",
        "        else:\n",
        "            flattened.append(str(element))\n",
        "    return flattened\n",
        "\n",
        "def generate_aq_responses(text_data):\n",
        "    aq_responses = []\n",
        "    for text in text_data:\n",
        "        responses = []\n",
        "        for _ in range(50):\n",
        "            response = random.choice([\"Definitely agree\", \"Slightly agree\", \"Slightly disagree\", \"Definitely disagree\"])\n",
        "            responses.append(response)\n",
        "        aq_responses.append(responses)\n",
        "    return aq_responses\n",
        "\n",
        "def calculate_aq_score(responses):\n",
        "    aq_score = 0\n",
        "    definitely_agree_items = [2, 4, 5, 6, 7, 9, 12, 13, 16, 18, 19, 20, 21, 22, 23, 26, 33, 35, 39, 41, 42, 43, 45, 46]\n",
        "    slightly_agree_items = [2, 4, 5, 6, 7, 9, 12, 13, 16, 18, 19, 20, 21, 22, 23, 26, 33, 35, 39, 41, 42, 43, 45, 46]\n",
        "    definitely_disagree_items = [1, 3, 8, 10, 11, 14, 15, 17, 24, 25, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 44, 47, 48, 49, 50]\n",
        "    slightly_disagree_items = [1, 3, 8, 10, 11, 14, 15, 17, 24, 25, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 44, 47, 48, 49, 50]\n",
        "\n",
        "    for i, response in enumerate(responses):\n",
        "        if response == \"Definitely agree\":\n",
        "            if i + 1 in definitely_agree_items:\n",
        "                aq_score += 1\n",
        "        elif response == \"Slightly agree\":\n",
        "            if i + 1 in slightly_agree_items:\n",
        "                aq_score += 1\n",
        "        elif response == \"Definitely disagree\":\n",
        "            if i + 1 in definitely_disagree_items:\n",
        "                aq_score += 1\n",
        "        elif response == \"Slightly disagree\":\n",
        "            if i + 1 in slightly_disagree_items:\n",
        "                aq_score += 1\n",
        "\n",
        "    return aq_score\n",
        "\n",
        "# Flatten the nested lists into a single list of strings\n",
        "all_data_flattened = [' '.join(flatten_list(doc)) for doc in all_data]\n",
        "\n",
        "# Generate approximate AQ responses based on the text data\n",
        "aq_responses = generate_aq_responses(all_data_flattened)\n",
        "\n",
        "# Calculate AQ scores for each individual based on the generated responses\n",
        "aq_scores = [calculate_aq_score(responses) for responses in aq_responses]\n",
        "\n",
        "# Preprocess the text data\n",
        "vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 3), min_df=5)\n",
        "X = vectorizer.fit_transform(all_data_flattened)\n",
        "y = np.array(all_label)  # Convert 'y' to a NumPy array\n",
        "\n",
        "# Combine AQ scores with text features\n",
        "X_combined = np.hstack((X.toarray(), np.array(aq_scores).reshape(-1, 1)))\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_combined = scaler.fit_transform(X_combined)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = [\n",
        "    LogisticRegression(class_weight='balanced'),\n",
        "    SVC(kernel='linear', class_weight='balanced'),\n",
        "    RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
        "]\n",
        "\n",
        "# Initialize stratified k-fold cross-validation\n",
        "kf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "# Perform 5-fold cross-validation for each classifier\n",
        "for classifier in classifiers:\n",
        "    print(f\"Classifier: {classifier.__class__.__name__}\")\n",
        "\n",
        "    after_accuracies=[]\n",
        "    after_f1_scores = []\n",
        "    after_sensitivities = []\n",
        "    after_specificities = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X_combined, y):\n",
        "        X_train, X_test = X_combined[train_index], X_combined[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Train the classifier\n",
        "        classifier.fit(X_train, y_train)\n",
        "\n",
        "        # Predict the labels for the test set\n",
        "        y_pred = classifier.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        acc=accuracy_score(y_test,y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        sensitivity = recall_score(y_test, y_pred)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "        specificity = tn / (tn + fp)\n",
        "\n",
        "        # Append scores to the lists\n",
        "        after_accuracies.append(acc)\n",
        "        after_f1_scores.append(f1)\n",
        "        after_sensitivities.append(sensitivity)\n",
        "        after_specificities.append(specificity)\n",
        "\n",
        "    # Print the average scores and standard deviations for each classifier\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(after_accuracies), np.std(after_accuracies) * 2))\n",
        "    print(\"F1 Score: %0.2f (+/- %0.2f)\" % (np.mean(after_f1_scores), np.std(after_f1_scores) * 2))\n",
        "    print(\"Sensitivity: %0.2f (+/- %0.2f)\" % (np.mean(after_sensitivities), np.std(after_sensitivities) * 2))\n",
        "    print(\"Specificity: %0.2f (+/- %0.2f)\" % (np.mean(after_specificities), np.std(after_specificities) * 2))\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
